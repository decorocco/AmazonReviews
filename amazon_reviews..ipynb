{
  "metadata": {
    "name": "amazon_reviews",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Projeto Spark\n## Alunos: André Rocco, Beatriz Muniz, Marcelo Miguel"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd \u003d sc.textFile(\u0027s3://megadados-alunos/dados/all_reviews_clean_tsv/\u0027).cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntype(rdd)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Tarefa 1\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Quantos reviews tem?"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(f\"há {rdd.count()} reviews nesse csv\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Quantos clientes existem"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d spark.read.option(\"header\", \"false\") \\\n    .option(\"delimiter\", \"\\t\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .csv(\"s3://megadados-alunos/dados/all_reviews_clean_tsv/\")\n    \ndf \u003d df \\\n    .withColumnRenamed(\"_c0\", \"marketplace\") \\\n    .withColumnRenamed(\"_c1\", \"customer_id\") \\\n    .withColumnRenamed(\"_c2\", \"review_id\") \\\n    .withColumnRenamed(\"_c3\", \"product_id\") \\\n    .withColumnRenamed(\"_c4\", \"product_parent\") \\\n    .withColumnRenamed(\"_c5\", \"product_title\") \\\n    .withColumnRenamed(\"_c6\", \"product_category\") \\\n    .withColumnRenamed(\"_c7\", \"star_rating\") \\\n    .withColumnRenamed(\"_c8\", \"helpful_votes\") \\\n    .withColumnRenamed(\"_c9\", \"total_votes\") \\\n    .withColumnRenamed(\"_c10\", \"vine\") \\\n    .withColumnRenamed(\"_c11\", \"verified_purchase\") \\\n    .withColumnRenamed(\"_c12\", \"review_headline\") \\\n    .withColumnRenamed(\"_c13\", \"review_body\") \\\n    .withColumnRenamed(\"_c14\", \"review_date\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf[[\u0027customer_id\u0027]].distinct().count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Quantos produtos existem"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf[[\u0027product_id\u0027]].distinct().count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Quantos reviews existem para cada “star_rating” (de 1 a 5 estrelas)?"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_star_rating_clean \u003d df.where((df[\u0027star_rating\u0027] \u003d\u003d\u00271\u0027) | (df[\u0027star_rating\u0027] \u003d\u003d\u00272\u0027) | (df[\u0027star_rating\u0027] \u003d\u003d\u00273\u0027)| (df[\u0027star_rating\u0027] \u003d\u003d\u00274\u0027)| (df[\u0027star_rating\u0027] \u003d\u003d\u00275\u0027))\n\ndf_star_rating_clean.groupBy(\"star_rating\").count().show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Tarefa 2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Tarefa 3"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import when\ndf_star_rating_clean \u003d df_star_rating_clean.na.drop()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import when\ndf_star_rating_clean\u003d df_star_rating_clean.withColumn(\"type_review\", when(df_star_rating_clean[\"star_rating\"] \u003d\u003d \"5\", \"positiva\")\\\n                    .when(df_star_rating_clean[\"star_rating\"] \u003d\u003d \"4\",\"neutra\").otherwise(\"negativa\"))\n                    "
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_star_rating_clean.groupBy(\"type_review\").count().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Import the required packages\nfrom pyspark.ml.feature import CountVectorizer\nfrom pyspark.ml.feature import Tokenizer, RegexTokenizer\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import NaiveBayes\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n# RegexTokenizer, CountVectorizer, StringIndexer e VectorAssembler\n# \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n\nstages \u003d []\n# 1. clean data and tokenize sentences using RegexTokenizer\nregexTokenizer \u003d RegexTokenizer(inputCol\u003d\"review_body\", outputCol\u003d\"tokens\", pattern\u003d\"\\\\W+\")\nstages +\u003d [regexTokenizer]\n\n# 2. CountVectorize the data\ncv \u003d CountVectorizer(inputCol\u003d\"tokens\", outputCol\u003d\"token_features\", minDF\u003d2.0)#, vocabSize\u003d3, minDF\u003d2.0\nstages +\u003d [cv]\n\n# 3. Convert the labels to numerical values using binariser\nindexer \u003d StringIndexer(inputCol\u003d\"type_review\", outputCol\u003d\"label\")\nstages +\u003d [indexer]\n\n# 4. Vectorise features using vectorassembler\nvecAssembler \u003d VectorAssembler(inputCols\u003d[\u0027token_features\u0027], outputCol\u003d\"features\")\nstages +\u003d [vecAssembler]\n[print(\u0027\\n\u0027, stage) for stage in stages]"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml import Pipeline\npipeline \u003d Pipeline(stages\u003dstages)\ndata \u003d pipeline.fit(df_star_rating_clean).transform(df_star_rating_clean)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntrain, test \u003d data.randomSplit([0.7, 0.3], seed \u003d 2018)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.classification import NaiveBayes\n# Initialise the model\nnb \u003d NaiveBayes(smoothing\u003d1.0, modelType\u003d\"multinomial\")\n# Fit the model\nmodel \u003d nb.fit(train)\n# Make predictions on test data\npredictions \u003d model.transform(test)\npredictions.select(\"label\", \"prediction\", \"probability\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nevaluator \u003d BinaryClassificationEvaluator(rawPredictionCol\u003d\"prediction\")\naccuracy \u003d evaluator.evaluate(predictions)\nprint (\"Model Accuracy: \", accuracy)"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid and Evaluator for Cross Validation\nparamGrid \u003d ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.5, 2.0]).build()\ncvEvaluator \u003d BinaryClassificationEvaluator(rawPredictionCol\u003d\"prediction\")\n\n# Run Cross-validation\ncv \u003d CrossValidator(estimator\u003dnb, estimatorParamMaps\u003dparamGrid, evaluator\u003dcvEvaluator)\ncvModel \u003d cv.fit(train)\n\n# Make predictions on testData. cvModel uses the bestModel.\ncvPredictions \u003d cvModel.transform(test)\n\n# Evaluate bestModel found from Cross Validation\nevaluator.evaluate(cvPredictions)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}